# Exploration of the perceptron storage capacity and manual implementation of a neural network 

## Overview

This project contains the analysis scripts and the reports for the course Neural Networks and Computational Intelligence, taken in 2025/2026 at the University of Groningen. The reports have been written in collaboration with a fellow student, listed below. The work consists of two assignments:

* **Assignment 1**: the storage capacity of the perceptron is explored. The project requires the implementation of Rosenblatt's perceptron training algorithm and the simulation of data sets on which binary classification is performed.
* **Assignment 3**: a shallow feed-forward neural network with a sigmoidal activation function is implemented manually via 'numpy'. The training of the network is through stochastic gradient descent, which is also manually implemented. The objective is to study the evolution of the training and the testing error with the number of training epochs, on a given data set. 

*Note*: there was a choice of two assignments out of three, which explains why the second assignment is labelled `Assignment3`.

## Project Structure
This project is organized as follows:

* **`Assignment1_code.ipynb`, `Assignment3_code.ipynb`**: The analysis scripts, in a Jupyter notebook format.
* **`Assignment1.pdf`, `Assignment3.pdf`**: The final reports in which the findings are presented and explained.
* **`tau1.csv`, `xi.csv`**: The data analysed in Assignment 3. It has been provided by the professor.

## Dependencies
* Python 3.12.12
* Libraries: numpy, matplotlib, scipy, pandas

See `requirements.txt` for exact versions.

## Author
Andrei-Rafael Secuiu / andrei.secuiu2@gmail.com

The reports have been written in collaboration with Roberto Schinina / roberto.schinina02@gmail.com

*Note*: The reports are written in collaboration, but the code is written by the author. 
